// Models Registry - Centr치ln칤 definice v코ech AI model콢
// Verze: 2.0 - S p콏idan칳mi Perplexity, Together AI a Cohere modely
// 
// Tento soubor obsahuje definice VECH dostupn칳ch model콢.
// Pro p콏id치n칤 nov칠ho modelu sta캜칤 p콏idat nov칳 objekt do pole MODELS_REGISTRY.

const MODELS_REGISTRY = [
    // === OPENAI MODELS ===
    {
        id: "gpt-3.5-turbo",
        provider: "openai",
        name: "GPT-3.5 Turbo",
        enabled: true,
        visible: true,
        config: {
            model: "gpt-3.5-turbo",
            contextWindow: 16384,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis"],
            description: "Rychl칳 a cenov캩 efektivn칤 model pro b캩쬹칠 칰lohy",
            endpoint: "https://api.openai.com/v1/chat/completions",
            assistant: true
        }
    },
    {
        id: "gpt-4",
        provider: "openai",
        name: "GPT-4",
        enabled: false,
        visible: false,
        config: {
            model: "gpt-4",
            contextWindow: 8192,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning", "coding"],
            description: "Nejv칳konn캩j코칤 model pro komplexn칤 칰lohy",
            endpoint: "https://api.openai.com/v1/chat/completions",
            assistant: false
        }
    },
    {
        id: "gpt-4-turbo-preview",
        provider: "openai",
        name: "GPT-4 Turbo",
        enabled: false,
        visible: false,
        config: {
            model: "gpt-4-turbo-preview",
            contextWindow: 128000,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning", "coding", "vision"],
            description: "Rychlej코칤 verze GPT-4 s v캩t코칤m kontextem",
            endpoint: "https://api.openai.com/v1/chat/completions",
            assistant: false
        }
    },
    {
        id: "gpt-4o-mini",
        provider: "openai",
        name: "GPT-4o Mini",
        enabled: true,
        visible: true,
        config: {
            model: "gpt-4o-mini",
            contextWindow: 128000,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning"],
            description: "Optimalizovan치 verze GPT-4 pro rychl칠 odpov캩di",
            endpoint: "https://api.openai.com/v1/chat/completions",
            assistant: true
        }
    },
    
    // === ANTHROPIC MODELS === (ZAK츼Z츼NO - CORS)
    {
        id: "claude-3-opus-20240229",
        provider: "anthropic",
        name: "Claude 3 Opus",
        enabled: false, // CORS blokuje
        visible: false,
        config: {
            model: "claude-3-opus-20240229",
            contextWindow: 200000,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning", "coding", "vision"],
            description: "Nejv칳konn캩j코칤 model od Anthropic",
            endpoint: "https://api.anthropic.com/v1/messages",
            assistant: false
        }
    },
    {
        id: "claude-3-5-sonnet-20241022",
        provider: "anthropic",
        name: "Claude 3.5 Sonnet",
        enabled: false, // CORS blokuje
        visible: false,
        config: {
            model: "claude-3-5-sonnet-20241022",
            contextWindow: 200000,
            maxTokens: 8192,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning", "coding", "vision"],
            description: "Nejnov캩j코칤 a nejchyt콏ej코칤 Claude model",
            endpoint: "https://api.anthropic.com/v1/messages",
            assistant: false
        }
    },
    {
        id: "claude-3-haiku-20240307",
        provider: "anthropic",
        name: "Claude 3 Haiku",
        enabled: false, // CORS blokuje
        visible: false,
        config: {
            model: "claude-3-haiku-20240307",
            contextWindow: 200000,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis"],
            description: "Rychl칳 a cenov캩 efektivn칤 model",
            endpoint: "https://api.anthropic.com/v1/messages",
            assistant: false
        }
    },
    
    // === PERPLEXITY MODELS ===
    {
        id: "pplx-7b-online",
        provider: "perplexity",
        name: "Perplexity 7B Online",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "pplx-7b-online",
            contextWindow: 4096,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "search", "analysis"],
            description: "Rychl칳 model s p콏칤stupem k aktu치ln칤m informac칤m z webu",
            endpoint: "https://api.perplexity.ai/chat/completions",
            onlineSearch: true
        }
    },
    {
        id: "pplx-70b-online",
        provider: "perplexity",
        name: "Perplexity 70B Online",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "pplx-70b-online",
            contextWindow: 4096,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "search", "analysis", "reasoning"],
            description: "V칳konn칳 model s p콏칤stupem k aktu치ln칤m informac칤m z webu",
            endpoint: "https://api.perplexity.ai/chat/completions",
            onlineSearch: true
        }
    },
    {
        id: "llama-3.1-sonar-small-128k-online",
        provider: "perplexity",
        name: "Llama 3.1 Sonar Small",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "llama-3.1-sonar-small-128k-online",
            contextWindow: 127072,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "search", "analysis"],
            description: "Llama model s velk칳m kontextem a online search",
            endpoint: "https://api.perplexity.ai/chat/completions",
            onlineSearch: true
        }
    },
    
    // === TOGETHER AI MODELS ===
    {
        id: "mistral-7b-instruct",
        provider: "together",
        name: "Mistral 7B Instruct",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "mistralai/Mistral-7B-Instruct-v0.2",
            contextWindow: 32768,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "coding"],
            description: "Rychl칳 open-source model s v칳bornou 캜e코tinou",
            endpoint: "https://api.together.xyz/v1/chat/completions",
            modelType: "instruct"
        }
    },
    {
        id: "mixtral-8x7b",
        provider: "together",
        name: "Mixtral 8x7B",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "mistralai/Mixtral-8x7B-Instruct-v0.1",
            contextWindow: 32768,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning", "coding"],
            description: "V칳konn칳 MoE model s vynikaj칤c칤 캜e코tinou",
            endpoint: "https://api.together.xyz/v1/chat/completions",
            modelType: "instruct"
        }
    },
    {
        id: "llama-2-70b-chat",
        provider: "together",
        name: "Llama 2 70B Chat",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "meta-llama/Llama-2-70b-chat-hf",
            contextWindow: 4096,
            maxTokens: 2048,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning"],
            description: "Velk칳 model od Meta s dobrou 캜e코tinou",
            endpoint: "https://api.together.xyz/v1/chat/completions",
            modelType: "chat",
            stopSequences: ["[/INST]", "</s>"]
        }
    },
    {
        id: "llama-3-70b-instruct",
        provider: "together",
        name: "Llama 3 70B Instruct",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            contextWindow: 8192,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning", "coding"],
            description: "Nejnov캩j코칤 Llama model s vylep코enou 캜e코tinou",
            endpoint: "https://api.together.xyz/v1/chat/completions",
            modelType: "instruct"
        }
    },
    
    // === COHERE MODELS ===
    {
        id: "command",
        provider: "cohere",
        name: "Command",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "command",
            contextWindow: 4096,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis"],
            description: "V칳konn칳 model pro konverzaci a anal칳zu",
            endpoint: "https://api.cohere.ai/v1/chat",
            preamble: "Jsi p콏치telsk칳 a n치pomocn칳 AI asistent. Odpov칤d치코 v 캜e코tin캩, pokud nen칤 po쬬dov치no jinak."
        }
    },
    {
        id: "command-light",
        provider: "cohere",
        name: "Command Light",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "command-light",
            contextWindow: 4096,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat"],
            description: "Rychl칳 a levn칳 model pro jednoduch칠 칰lohy",
            endpoint: "https://api.cohere.ai/v1/chat"
        }
    },
    {
        id: "command-r",
        provider: "cohere",
        name: "Command R",
        enabled: false, // Zm캩켿te na true a budete m칤t API kl칤캜
        visible: false,
        config: {
            model: "command-r",
            contextWindow: 128000,
            maxTokens: 4096,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "search"],
            description: "Model s velk칳m kontextem a RAG schopnostmi",
            endpoint: "https://api.cohere.ai/v1/chat",
            connectors: [] // M콢쬰 pou쮂셨at web search
        }
    },
    
    // === GOOGLE MODELS === (P콎IPRAVENO PRO BUDOUCNOST)
    {
        id: "gemini-pro",
        provider: "google",
        name: "Gemini Pro",
        enabled: false,
        visible: false,
        config: {
            model: "gemini-pro",
            contextWindow: 32000,
            maxTokens: 8192,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "reasoning"],
            description: "Google Gemini Pro model",
            endpoint: "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent",
            assistant: false
        }
    },
    {
        id: "gemini-1.5-pro",
        provider: "google",
        name: "Gemini 1.5 Pro",
        enabled: false,
        visible: false,
        config: {
            model: "gemini-1.5-pro-latest",
            contextWindow: 1000000,
            maxTokens: 8192,
            temperature: 0.7,
            capabilities: ["chat", "analysis", "vision", "long-context"],
            description: "Google Gemini s obrovsk칳m kontextov칳m oknem",
            endpoint: "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent",
            assistant: false
        }
    }
];

// Helper funkce pro pr치ci s registry
const ModelsRegistryHelper = {
    // Z칤skat v코echny modely
    getAllModels() {
        return MODELS_REGISTRY;
    },
    
    // Z칤skat pouze povolen칠 modely
    getEnabledModels() {
        return MODELS_REGISTRY.filter(model => model.enabled);
    },
    
    // Z칤skat modely podle providera
    getModelsByProvider(provider) {
        return MODELS_REGISTRY.filter(model => model.provider === provider);
    },
    
    // Z칤skat model podle ID
    getModelById(modelId) {
        return MODELS_REGISTRY.find(model => model.id === modelId);
    },
    
    // Z칤skat v칳choz칤 viditeln칠 modely
    getDefaultVisibleModels() {
        return MODELS_REGISTRY.filter(model => model.enabled && model.visible);
    },
    
    // Validovat model ID
    isValidModelId(modelId) {
        return MODELS_REGISTRY.some(model => model.id === modelId);
    },
    
    // Z칤skat seznam provider콢
    getProviders() {
        const providers = new Set(MODELS_REGISTRY.map(model => model.provider));
        return Array.from(providers);
    }
};

// Export pro pou쬴t칤 v jin칳ch souborech
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { MODELS_REGISTRY, ModelsRegistryHelper };
} else {
    window.MODELS_REGISTRY = MODELS_REGISTRY;
    window.ModelsRegistryHelper = ModelsRegistryHelper;
}

console.log('游늶 Models Registry loaded with', MODELS_REGISTRY.length, 'models');
